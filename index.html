<!DOCTYPE html>
<html lang="en">
<head>
    <title>Jian Yang</title>
    <!-- Meta -->
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="">
    <meta name="author" content="Xiaoying Riley at 3rd Wave Media">
    <link rel="shortcut icon" href="images/map_icon.png">

    <link href='https://fonts.googleapis.com/css?family=Lato:300,400,300italic,400italic' rel='stylesheet' type='text/css'>
    <link href='https://fonts.googleapis.com/css?family=Montserrat:400,700' rel='stylesheet' type='text/css'>

    <!-- FontAwesome JS -->
    <script defer src="assets/fontawesome/js/all.js"></script>

    <!-- Global CSS -->
    <link rel="stylesheet" href="assets/plugins/bootstrap/css/bootstrap.min.css">

    <!-- github calendar css -->
    <!-- <link rel="stylesheet" href="assets/plugins/github-calendar/dist/github-calendar-responsive.css"> -->
    <!-- github activity css -->
    <!-- <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/octicons/2.0.2/octicons.min.css"> -->
    <!-- <link rel="stylesheet" href="assets/plugins/github-activity/src/github-activity.css"> -->

    <!-- Theme CSS -->
    <link id="theme-style" rel="stylesheet" href="assets/css/styles.css">

</head>

<body>
    <!-- ******HEADER****** -->
    <header class="header">
        <div class="container">
	        <div class="row align-items-center">
			    <div class="col">
		            <!-- <img class="profile-image img-fluid float-start rounded-circle" src="images/jianyang.png" alt="profile image" /> -->
                    <img class='profile-image img-fluid float-start rounded-circle' src="images/jianyang.png" alt="profile image"
                        onmouseover="this.src='images/jianyang.png'"
                        onmouseout="this.src='images/jianyang.png'" />
		            <div class="profile-content">
		                <h1 class="name">Jian Yang</h1>
		                <!-- <h2 class="desc">Web App Developer</h2> -->
		                <ul class="social list-inline">
		                    <!-- <li class="list-inline-item"><a href="https://twitter.com/xinntao" target="_blank"><i class="fab fa-twitter"></i></a></li> -->
		                    <!-- <li class="list-inline-item"><a href="#"><i class="fab fa-linkedin-in"></i></a></li> -->
                            <li class="list-inline-item"><a href="https://scholar.google.com/citations?user=yFI_RjUAAAAJ&hl=en" target="_blank"><i class="fab fa-google"></i></a></li>
		                    <li class="list-inline-item"><a href="https://github.com/liujiaheng" target="_blank"><i class="fab fa-github"></i></a></li>
		                    <li class="list-inline-item"><a href="email.html" target="_blank"><i class="fas fa-envelope-square"></i></a></li>
                            <li class="list-inline-item last-item"><a href="https://www.zhihu.com/people/liu-jia-heng-12" target="_blank"><i class="fab fa-zhihu"></i></a></li>
                                <!-- <div class="icon-with-text">
                                <i class="fa fa-fw"></i>
                                <span class="text">语雀</span>
                                </div></a></li> -->

                            <!-- <li class="list-inline-item last-item"><a href="https://www.yuque.com/xinntao" target="_blank"><i class="fab fa-yuque"></i></a></li> -->

		                </ul>
		            </div><!--//profile-->
			    </div><!--//col-->
	            <div class="col-12 col-md-auto">
		            <div class="dark-mode-switch d-flex">
						<div class="form-check form-switch mx-auto mx-md-0">
							<!-- <input type="checkbox" class="form-check-input me-2" id="darkSwitch" checked/> -->
                            <input type="checkbox" class="form-check-input me-2" id="darkSwitch"/>
							<label class="custom-control-label" for="darkSwitch">Dark Mode</label>
						</div>
			        </div><!--//dark-mode-switch-->
	                <a class="btn btn-cta-primary" href="email.html" target="_blank"><i class="fas fa-paper-plane"></i> Contact Me</a>
	            </div><!--//col-->
	        </div><!--//row-->
        </div><!--//container-->
    </header><!--//header-->

    <div class="container sections-wrapper py-5">
        <div class="row">
            <div class="primary col-lg-8 col-12">
                <section class="about section">
                    <div class="section-inner shadow-sm rounded">
                        <!-- <h2 class="heading">About Me</h2> -->
                        <div class="content">
                            <!-- https://github.com/KwaiVGI -->
			    I obtained my B.S. degree and Ph.D. at Beihang University, as a joint Phd student between Beihang University and Microsoft Research Asia (MSRA), supervised by <a href="https://scse.buaa.edu.cn/info/1078/2655.htm" target="_blank">Prof. Zhoujun Li</a> and Dr. <a href="https://scse.buaa.edu.cn/info/1078/2655.htm" target="_blank">Ming Zhou</a>. 
                            I am currently a Research Scientist at Alibaba Qwen Team, focusing on <b>Large Language Models (LLMs)</b>, including <b>code, pos-training, and reasoning</b>.<br>
                            </p>
                            <p align="left">
                                Microsoft Research Asia (Mentor: Dongdong Zhang and Shuming Ma): 2018-2023 <br>
				Ubiquant: 2023 <br>
				Alibaba Qwen: 2023-Now <br>

                            </p>
                        </div><!--//content-->
                    </div><!--//section-inner-->
                </section><!--//section-->

                <section class="about section">
                    <div class="section-inner shadow-sm rounded">
                        <!-- <h2 class="heading">About Me</h2> -->
                        <div class="content">
                            <p align="left">
                            <font color="orange"><b>● Large Language Models</b></font>
                            <ul>
                                <li><b>Post-training</b>: RoleLLM (ACL Findings 2024), etc</li>
                                <li><b>Code</b>: Qwen2.5-Coder, UniCoder (ACL 2024), CodeArena, ExecRepoBench, xCoder, McEval (ICLR 2025), MdEval, etc</li>
                                <li><b>Evaluation </b>: OWL (ICLR 2024), KORBench (ICLR 2025), etc</li>
                            </ul>
                            <font color="orange"><b>● Natural Language Processing</b></font>
                            <ul>
                                <li><b>Understanding</b>: CROP (Finding of EMNLP 2022)</li>
                                <li><b>Generation</b>: GanLM (ACL 2022), GTrans (TASLP 2022) </li>
                            </ul>
                        </div><!--//content-->
                    </div><!--//section-inner-->
                </section><!--//section-->

<!--=====================================================  News  ====================================================-->
                <section class="projects section">
                    <div class="section-inner shadow-sm rounded">
                        <h2 class="heading">News</h2>
                        <div class="item-content">
                            <ul class="resume-list" style="list-style: outside;list-style-type: square;">
				<li> <b>[1/2025]</b> Four papers are accepted to ICLR 2025.</li>
<!-- 
                                <li> <b>[10/2023]</b> Ranked as <a href="https://elsevier.digitalcommonsdata.com/datasets/btchxktzyw/6" target="_blank">Top 2% Scientists Worldwide 2023</a> (Single Year) by Stanford University.</li>
                                <li> <b>[10/2023]</b> Two papers are accepted to NeurIPS 2023.</li>
                                <li> <b>[09/2023]</b> Release <a href="https://github.com/TencentARC/T2I-Adapter" target="_blank">T2I-Adapter</a> for SDXL: the most efficient control models, collaborating with <a href="https://huggingface.co/blog/t2i-sdxl-adapters" target="_blank">HuggingFace</a>.</li>
                                <li> <b>[07/2023]</b> Three papers are accepted to ICCV 2023.</li>
                                <li> <b>[04/2023]</b> One paper is accepted to ICML 2023.</li>
                                <li> <b>[03/2023]</b> We are holding the <a href="https://github.com/360SR/360SR-Challenge" target="_blank">360° Super-Resolution Challenge</a> as a part of the <a href="https://cvlai.net/ntire/2023/" target="_blank">NTIRE workshop</a> in conjunction with CVPR 2023.</li>
                                <li> <b>[02/2023]</b> Three papers to appear in CVPR 2023.</li>
                                <li> <b>[11/2022]</b> Two papers to appear in AAAI 2023.</li>
                                <li> <b>[09/2022]</b> Ranked as <a href="https://elsevier.digitalcommonsdata.com/datasets/btchxktzyw/5" target="_blank">Top 2% Scientists Worldwide 2022</a> (Single Year) by Stanford University.</li>
                                <li> <b>[09/2022]</b> Two papers to appear in NeurIPS 2022.</li>
                                <li> <b>[07/2022]</b> Two papers to appear in ECCV 2022. VQFR is accepted as <font color="orange">oral</font> (2.7%).</li>
                                <li> <b>[06/2022]</b> Two papers to appear in ACM MM 2022.</li>
                                <li> <b>[05/2022]</b> BasicSR joins the <a href="https://github.com/XPixelGroup" target="_blank">XPixel Group</a>!</li>
                                <li> <b>[04/2022]</b> We release a high-quality face video dataset (VFHQ). Please refer to the <a href="https://liangbinxie.github.io/projects/vfhq">project page</a> and <a href="https://arxiv.org/abs/2205.03409">our paper</a>.</li>
                                <li> <b>[12/2021]</b> One paper to appear in NeurIPS 2021 as <font color="orange">spotlight</font> (2.85%): <a href="https://proceedings.neurips.cc/paper/2021/hash/008bd5ad93b754d500338c253d9c1770-Abstract.html">FAIG: Finding Discriminative Filters for Specific Degradations in Blind Super-Resolution</a>. Codes are released in <a href="https://github.com/TencentARC/FAIG">TencentARC/FAIG</a>.</li>
                                <li> <b>[10/2021]</b> <a href="https://arxiv.org/abs/2107.10833">Real-ESRGAN</a> is accepted by ICCV 2021 AIM workshop with Honorary Nomination Paper Award.</li> -->
                                <!-- <details>
                                    <summary>Click for More</summary>
                                <li> [07/2021] One paper to appear in ICCV 2021: <a href="https://arxiv.org/abs/2108.08826">Towards Vivid and Diverse
                                    Image Colorization with Generative Color Prior</a>
                                </li>
                                <li> [07/2021] The codes for practical image restoration <a href="https://arxiv.org/abs/2107.10833">Real-ESRGAN</a>
                                    are released on <a href="https://github.com/xinntao/Real-ESRGAN">Github</a>.
                                </li>
                                <li> [06/2021] The training and testing codes of GFPGAN are released on <a
                                    href="https://github.com/TencentARC/GFPGAN">TencentARC</a>.
                                </li>
                                <li> [03/2021] 5 papers to appear in CVPR 2021.
                                </li>
                                <li> [03/2021] A brand-new <a href="https://github.com/xinntao/HandyView">HandyView</a> online!.
                                </li>
                                <li> [08/2020] A brand-new <a href="https://github.com/xinntao/BasicSR">BasicSR</a> v1.0.0 online!
                                </li>
                                <li> [06/2019] We have released the <a href="https://github.com/xinntao/EDVR">EDVR</a> training and testing codes
                                    and also updated <a href="https://github.com/xinntao/BasicSR">BasicSR</a> codes!
                                </li>
                                <li> [06/2019] Got my first outstanding reviewer recognition from CVPR 2019!
                                </li>
                                <li> [05/2019] Our video restoration method, <b>EDVR</b>, won all four tracks in the <a
                                    href="http://www.vision.ee.ethz.ch/ntire19/">NTIRE 2019 video restoration and enhancement challenges</a>.
                                    Check <a href="https://arxiv.org/abs/1905.02716">our paper</a> for more details.
                                </li>
                                <li> [03/2019] Our paper <a href="https://xinntao.github.io/projects/DNI"><i>Deep Network Interpolation for
                                        Continuous Imagery Effect Transition</i></a> to appear in CVPR 2019.
                                </li>
                                <li> [08/2018] Our SuperSR team won the third track of the <a href="https://www.pirm2018.org/PIRM-SR.html">2018
                                    PIRM Challenge on Perceptual Super-Resolution</a>. Check the report <a
                                    href="https://arxiv.org/abs/1809.00219"><i>ESRGAN</i></a> for more details.
                                </li>
                                <li> [06/2018] We won the <a href="http://www.vision.ee.ethz.ch/ntire17/NTIRE">NTIRE 2018 Challenge on Single Image
                                    Super-Resolution</a> as first runner-up and ranked the first in the <i>Realistic Wild ×4 conditions</i>
                                    track.
                                </li>
                                <li> [02/2018] Our paper <a href="http://mmlab.ie.cuhk.edu.hk/projects/SFTGAN/"><i>Recovering Realistic Texture in
                                        Image Super-resolution by Deep Spatial Feature Transform</i></a> to appear in CVPR 2018.
                                </li>
                                <li> [07/2017] Our HelloSR team won the <a href="http://www.vision.ee.ethz.ch/ntire17/NTIRE">NTIRE 2017 Challenge
                                    on Single Image Super-Resolution</a> as first runner-up.
                                </li>
                                </details> -->
                            </ul>
                        </div><!--//content-->
                    </div><!--//section-inner-->
                </section><!--//section-->


<!--=====================================================  Publications  ====================================================-->
               <section class="latest section">
                    <div class="section-inner shadow-sm rounded">
                        <h2 class="heading">Publications <a href="https://scholar.google.com/citations?user=yFI_RjUAAAAJ&hl=en" target="_blank">[Full List]</a></h2>
                        <div class="content">
                                <small>(* equal contribution, <sup>#</sup> corresponding author)</small>
                        <br>
                        <ul class="resume-list" style="list-style: outside;list-style-type: square;">
                            <li>
                            PTSBench: A Comprehensive Post-Training Sparsity Benchmark Towards Algorithms and Models</br>
                                Zining Wang, Jinyang Guo, Ruihao Gong, Yang Yong, Aishan Liu, Yushi Huang, <b>Jiaheng Liu</b>, Xianglong Liu</br>
                                   ACM Multimedia (<b>ACM MM</b>), 2024 </br>
                                    <p></p>
                                </li>	
                            <font color="#49ac43"><b>To be updated</b></font>
                        </ul>


                        </div><!--//content-->
                    </div><!--//section-inner-->
                </section><!--//section-->

            </div><!--//primary-->
            
            <div class="secondary col-lg-4 col-12">
                 <aside class="info aside section">
                    <div class="section-inner shadow-sm rounded">
                        <h2 class="heading sr-only">Basic Information</h2>
                        <div class="content">
                            <ul class="list-unstyled">
                                <li><i class="fas fa-envelope"></i><span class="sr-only">Email:</span><a href="email.html">ljh411989@alibaba-inc.com</a></li>
                                <li><i class="fab fa-google"></i><span class="sr-only">Google Scholar:</span><a href="https://scholar.google.com/citations?user=yFI_RjUAAAAJ&hl=en">Google Scholar</a></li>
                                <li><i class="fab fa-github"></i><span class="sr-only">GitHub:</span><a href="https://github.com/liujiaheng">GitHub</a></li>
                                <li><i class="fas fa-map-marker-alt"></i><span class="sr-only">Location:</span>Beijing, China</li>
                                <!-- <li><i class="fas fa-link"></i><span class="sr-only">Website:</span><a href="#">https://www.website.com</a></li> -->
                            </ul>
                        </div><!--//content-->
                    </div><!--//section-inner-->
                </aside><!--//aside-->

                <aside class="education aside section">
                    <div class="section-inner shadow-sm rounded">
                        <h2 class="heading">Education</h2>
                        <div class="content">
                            <div class="item">
                                <h3 class="title"><i class="fas fa-graduation-cap"></i> Ph.D. in Beihang University, <span class="year">2019-2023</span></h3>
                                <!-- <h4 class="university"><a href="http://mmlab.ie.cuhk.edu.hk/" target="_blank">Multimedia
              Laboratory (MMLab)</a>,<br>
            <a href="https://www.cuhk.edu.hk/english/index.html" target="_blank">Beihang University</a>, <span class="year">2016-2020</span></h4> -->
                            </div><!--//item-->
                            <div class="item">
                                <h3 class="title"><i class="fas fa-graduation-cap"></i> B.Eng. in Beihang University, <span class="year">2015-2019</span></h3>
                            </div><!--//item-->
                        </div><!--//content-->
                    </div><!--//section-inner-->
                </aside><!--//section-->

                
            </div><!--//secondary-->
        </div><!--//row-->
    </div><!--//masonry-->

    <!-- ******FOOTER****** -->
    <footer class="footer">
        <div class="container text-center">
                <!--/* This template is free as long as you keep the attribution link below. Thank you for your support. :) If you'd like to use the template without the attribution, you can buy the commercial license via our website: themes.3rdwavemedia.com */-->
                <small class="copyright">This template is modified from <a href="https://themes.3rdwavemedia.com/demo/bs5/developer/" target="_blank">Xiaoying Riley's project</a></small>
        </div><!--//container-->
    </footer><!--//footer-->

    <!-- Javascript -->
    <script type="text/javascript" src="assets/plugins/popper.min.js"></script>
    <script type="text/javascript" src="assets/plugins/bootstrap/js/bootstrap.min.js"></script>
    <script type="text/javascript" src="assets/plugins/vanilla-rss/dist/rss.global.min.js"></script>
    <script type="text/javascript" src="assets/plugins/dark-mode-switch/dark-mode-switch.min.js"></script>
    <!-- custom js -->
    <script type="text/javascript" src="assets/js/main.js"></script>
</body>
</html>
